# @package _global_
defaults:
- /model: mime
- /dataset: harmc
- /datamodule: mime_datamodule
- /trainer: single_gpu_trainer
- /metric:
  - accuracy
  - auroc
- /hydra: experiment
- _self_
    
# Mandatory Configuration Parameters
model:
  cls_dict: 
    intensity: 3
  optimizers: 
  - class_path: torch.optim.Adam
    lr: 2e-5

dataset:
  dataset_class: datasets.harmc.MimeDataset
  text_template: "{caption}"
  labels:
  - intensity
  auxiliary_dicts:
    train:
      # interpretation: /mnt/sda/mshee/datasets/memes/harmc/interpretations/InstructBLIP.json
      caption: /mnt/sda/mshee/datasets/memes/harmc/captions/InstructBLIP.json
    validate:
      # interpretation: /mnt/sda/mshee/datasets/memes/harmc/interpretations/InstructBLIP.json
      caption: /mnt/sda/mshee/datasets/memes/harmc/captions/InstructBLIP.json
    test:
      # interpretation: /mnt/sda/mshee/datasets/memes/harmc/interpretations/InstructBLIP.json
      caption: /mnt/sda/mshee/datasets/memes/harmc/captions/InstructBLIP.json
    predict:
      # interpretation: /mnt/sda/mshee/datasets/memes/harmc/interpretations/InstructBLIP.json
      caption: /mnt/sda/mshee/datasets/memes/harmc/captions/InstructBLIP.json
    

datamodule:
  multimodal_tokenizer_class_or_path: facebook/flava-full
  rc_tokenizer_class_or_path: roberta-large
  frcnn_class_or_path: None

monitor_metric: validate_intensity_average
monitor_mode: max
save_top_ks: 1

# Experiment settings
experiment_name: harmc/mime_InstructBLIP_caption
model_checkpoint: /mnt/sda/mshee/MATK/experiments/harmc/mime_InstructBLIP_caption/seed_everything=1111/epoch=4-step=475.ckpt

# Job settings
hydra.verbose: True
seed_everything: 1111
overwrite: False
action: ???